{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24922ac6-09bb-4008-a91e-5fa321999a77",
   "metadata": {},
   "source": [
    "### Explainability API ## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa800630-7ed1-4ac4-ac15-6e39dbb68cb7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b841996e-826f-430e-a831-c35dd6658b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from cyclops.processors.column_names import EVENT_NAME\n",
    "from cyclops.utils.file import load_pickle\n",
    "from models.temporal.optimizer import Optimizer, EarlyStopper\n",
    "from models.temporal.utils import (\n",
    "    get_data,\n",
    "    get_device,\n",
    "    get_temporal_model,\n",
    "    load_checkpoint,\n",
    ")\n",
    "\n",
    "from models.temporal.metrics import print_metrics_binary\n",
    "from drift_detection.gemini.utils import prep, get_use_case_params, import_dataset_hospital, random_shuffle_and_split\n",
    "from drift_detection.drift_detector.plotter import plot_pretty_confusion_matrix\n",
    "from drift_detection.gemini.constants import DIAGNOSIS_DICT, HOSPITALS\n",
    "from models.static.utils import run_model\n",
    "from drift_detection.drift_detector.explainer import Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741632c0-aa41-4553-bbb2-eb6fee0b083a",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae4fe6a7-a812-444a-b1c0-618ae3cdde1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select diagnosis trajectory to filter on:  all\n",
      "Select hospital to filter on:  all\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"gemini\"\n",
    "USE_CASE = \"mortality\"\n",
    "DIR=os.path.join(\"/mnt/nfs/project/delirium/drift_exp/OCT-18-2022/gemini\",USE_CASE,\"saved_models\")\n",
    "ID = SPLIT = \"seasonal_winter\"#input(\"Select data split: \")\n",
    "DIAGNOSIS_TRAJECTORY = input(\"Select diagnosis trajectory to filter on: \") \n",
    "HOSPITAL = input(\"Select hospital to filter on: \") \n",
    "\n",
    "splice_map = {\n",
    "    \"hospital_id\": HOSPITALS\n",
    "}\n",
    "\n",
    "if DIAGNOSIS_TRAJECTORY != \"all\":\n",
    "    diagnosis_trajectory = '_'.join(DIAGNOSIS_DICT[DIAGNOSIS_TRAJECTORY])\n",
    "    ID = ID +\"_\"+ diagnosis_trajectory\n",
    "    splice_map[\"diagnosis_trajectory\"] = [diagnosis_trajectory]\n",
    "    \n",
    "if HOSPITAL != \"all\":\n",
    "    ID = HOSPITAL + \"_\" + ID \n",
    "    splice_map[\"hospital_id\"] = [HOSPITAL]\n",
    "    \n",
    "use_case_params = get_use_case_params(DATASET, USE_CASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d94c22b-31a7-4a05-809a-ffbfee47bafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 00:01:28,525 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/drift_exp/OCT-18-2022/gemini/mortality/./data/4-final/aligned_comb_train_X_seasonal_winter.pkl\n",
      "2023-01-31 00:01:28,910 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/drift_exp/OCT-18-2022/gemini/mortality/./data/4-final/aligned_comb_train_y_seasonal_winter.pkl\n",
      "2023-01-31 00:01:28,949 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/drift_exp/OCT-18-2022/gemini/mortality/./data/4-final/aligned_comb_val_X_seasonal_winter.pkl\n",
      "2023-01-31 00:01:29,050 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/drift_exp/OCT-18-2022/gemini/mortality/./data/4-final/aligned_comb_val_y_seasonal_winter.pkl\n",
      "2023-01-31 00:01:29,063 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/drift_exp/OCT-18-2022/gemini/mortality/./data/4-final/aligned_comb_test_X_seasonal_winter.pkl\n",
      "2023-01-31 00:01:29,307 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/drift_exp/OCT-18-2022/gemini/mortality/./data/4-final/aligned_comb_test_y_seasonal_winter.pkl\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "X_train_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_train_X_\"+ID)\n",
    "y_train_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_train_y_\"+ID)\n",
    "X_val_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_val_X_\"+ID)\n",
    "y_val_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_val_y_\"+ID)\n",
    "X_test_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_test_X_\"+ID)\n",
    "y_test_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_test_y_\"+ID)\n",
    "\n",
    "X_train = prep(X_train_vec.data)\n",
    "y_train = prep(y_train_vec.data)\n",
    "X_val = prep(X_val_vec.data)\n",
    "y_val = prep(y_val_vec.data)\n",
    "X_test = prep(X_test_vec.data)\n",
    "y_test = prep(y_test_vec.data)\n",
    "\n",
    "(X_train, y_train), (X_val, y_val) = random_shuffle_and_split(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa1e26-3102-48ba-b604-3f8c653906ab",
   "metadata": {},
   "source": [
    "## Get temporal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "741c380e-264e-4f1c-a0d7-3570d725b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 1\n",
    "batch_size = 64\n",
    "input_dim = X_train.shape[2]\n",
    "timesteps = X_train.shape[1]\n",
    "hidden_dim = 64\n",
    "layer_dim = 2\n",
    "dropout = 0.2\n",
    "n_epochs = 128\n",
    "learning_rate = 2e-3\n",
    "weight_decay = 1e-6\n",
    "last_timestep_only = False\n",
    "device = get_device()\n",
    "\n",
    "model_params = {\n",
    "    \"device\": device,\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"layer_dim\": layer_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"dropout_prob\": dropout,\n",
    "    \"last_timestep_only\": last_timestep_only,\n",
    "}\n",
    "\n",
    "model_name = \"lstm\"\n",
    "model = get_temporal_model(model_name, model_params).to(device)\n",
    "\n",
    "filepath=os.path.join(DIR,ID+\"_reweight_positive\"+\"_\"+model_name+\"_\"+str(seed)+\".pt\")\n",
    "if os.path.exists(filepath):\n",
    "    model, opt, n_epochs = load_checkpoint(filepath, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46ce9497-f749-42ca-84d7-c2aaf58db28c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m shapvalues \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_val[:\u001b[38;5;241m500\u001b[39m])\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KKtuQLwg-py3.9/lib/python3.9/site-packages/shap/explainers/_deep/__init__.py:86\u001b[0m, in \u001b[0;36mDeep.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m TFDeep(model, data, session, learning_phase_flags)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mPyTorchDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mexpected_value\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KKtuQLwg-py3.9/lib/python3.9/site-packages/shap/explainers/_deep/deep_pytorch.py:54\u001b[0m, in \u001b[0;36mPyTorchDeep.__init__\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 54\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# also get the device everything is running on\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KKtuQLwg-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cyclops/drift_detection/baseline_models/temporal/pytorch/models.py:195\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 195\u001b[0m         torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_dim, \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m     c0 \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    200\u001b[0m         torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_dim, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    204\u001b[0m     out, (_, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x, (h0\u001b[38;5;241m.\u001b[39mdetach(), c0\u001b[38;5;241m.\u001b[39mdetach()))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "explainer = shap.DeepExplainer(model, X_train[:500])\n",
    "shapvalues = explainer.shap_values(X_val[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032f5f1-84cf-4f1c-9a53-de86dc490e09",
   "metadata": {},
   "source": [
    "## Get static model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b46bcac-41cb-4326-a7f2-2cdc7f8f740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = input(\"Select Model: \")\n",
    "MODEL_PATH = PATH + \"_\".join([SHIFT, OUTCOME, \"_\".join(HOSPITALS), MODEL_NAME]) + \".pkl\"\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    optimised_model = pickle.load(open(MODEL_PATH, \"rb\"))\n",
    "else:\n",
    "    optimised_model = run_model(MODEL_NAME, X_tr_final, y_tr, X_val_final, y_val)\n",
    "    pickle.dump(optimised_model, open(MODEL_PATH, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7697a7b-7aa6-4ffc-8dd7-921474bcdf31",
   "metadata": {},
   "source": [
    "## Explain difference in static model predictions ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2af7f8-5f0c-4cd5-b7f2-7ab07662e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(optimised_model, X_tr_final)\n",
    "explainer.get_explainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b809f2-d434-4905-8fc6-7489057de217",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = [\"T1_\", \"T2_\", \"T3_\", \"T4_\", \"T5_\", \"T6_\"]\n",
    "\n",
    "flattened_feats = []\n",
    "for ts in timesteps:\n",
    "    flattened_feats.append(ts + feats)\n",
    "flattened_feats = list(itertools.chain.from_iterable(flattened_feats))\n",
    "\n",
    "X_val_df = pd.DataFrame(X_val_final, columns=flattened_feats)\n",
    "val_shap_values = explainer.get_shap_values(X_val_df)\n",
    "X_test_df = pd.DataFrame(X_t_final, columns=flattened_feats)\n",
    "test_shap_values = explainer.get_shap_values(X_test_df)\n",
    "\n",
    "shap_diff = np.mean(np.abs(test_shap_values.values), axis=0) - np.mean(\n",
    "    np.abs(val_shap_values.values), axis=0\n",
    ")\n",
    "shap_min = -0.001\n",
    "shap_max = 0.001\n",
    "shap_diff_sorted, feats_sorted = zip(\n",
    "    *sorted(zip(shap_diff, flattened_feats), reverse=True)\n",
    ")\n",
    "shap_diff_sorted, feats_sorted = zip(\n",
    "    *(\n",
    "        (\n",
    "            (x, y)\n",
    "            for x, y in zip(shap_diff_sorted, feats_sorted)\n",
    "            if (x > shap_max or x < shap_min)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "shap_feats = {\"feature\": feats_sorted, \"shap_diff\": list(shap_diff_sorted)}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 18))\n",
    "y_pos = np.arange(len(shap_feats[\"shap_diff\"]))\n",
    "ax.barh(y_pos, shap_feats[\"shap_diff\"], align=\"center\")\n",
    "ax.set_yticks(y_pos, labels=shap_feats[\"feature\"])\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel(\"Mean Difference in Shap Value\")\n",
    "ax.set_title(\"Features\")\n",
    "plt.show()\n",
    "\n",
    "shap_diff_sorted, feats_sorted = zip(\n",
    "    *sorted(zip(shap_diff, flattened_feats), reverse=True)\n",
    ")\n",
    "shap_diff_sorted, feats_sorted = zip(\n",
    "    *(((x, y) for x, y in zip(shap_diff_sorted, feats_sorted) if (x != 0)))\n",
    ")\n",
    "\n",
    "for t in [\"T1_\", \"T2_\", \"T4_\", \"T4_\", \"T5_\", \"T6_\"]:\n",
    "    shap_feats = {\"feature\": feats_sorted, \"shap_diff\": list(shap_diff_sorted)}\n",
    "    shap_feats = {\n",
    "        k: [\n",
    "            x\n",
    "            for i, x in enumerate(v)\n",
    "            if any(ts in shap_feats[\"feature\"][i] for ts in [t])\n",
    "        ]\n",
    "        for k, v in shap_feats.items()\n",
    "    }\n",
    "    shap_feats[\"feature\"] = list(map(lambda x: x.replace(t, \"\"), shap_feats[\"feature\"]))\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    y_pos = np.arange(len(shap_feats[\"shap_diff\"]))\n",
    "    ax.barh(y_pos, shap_feats[\"shap_diff\"], align=\"center\")\n",
    "    ax.set_yticks(y_pos, labels=shap_feats[\"feature\"])\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_xlabel(\"Mean Difference in Shap Value |Target - Source|\")\n",
    "    ax.set_title(\"Features\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops-KKtuQLwg-py3.9",
   "language": "python",
   "name": "cyclops-kktuqlwg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd2cd438e1c6ddffa3035fc73b17ac5cc0e0ea8897eb8be17cc645c6abf0c8cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
